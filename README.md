# miniature-spork
## Neurobio140 Project

Artificial intelligence (AI) image creation has recently become a mainstream way for amateurs to create artworks and images online with just a sentence or two of instruction (Roose, 2022). The technology is fascinating but controversial, as it raises concerns about originality and the ethics of generating content without the direct influence of human creativity. As AI models become increasingly sophisticated, the line has blurred between human and machine-created art, leading to lawsuits over intellectual property, questions about the future of creative professions, and a potential new definition of art (Feldman, 2023). 

Text-based AI models have a similar difficulty keeping out of trouble, as noted by Uchendu et al., (2020) who created a model to compare different LMs’ (language model) generated text and predict the LM that generated it, which is imperative to detect and stop fraud, as AI models “may use such technologies to generate realistic artifacts to trick naive users in fraudulent activities (e.g., machine-generated chatbot conversation in a phishing scam).” AI generated images have serious implications for impersonation scams or misinformation campaigns. These images can create fake identities, manipulate public opinion, or even influence political events (Bontridder & Poullet, 2021).

The differences between AI generated text (synthetic) and human text (organic), are already quite apparent and accurately testable using easily accessible websites like GPTZero.com, as are the differences between synthetic and organic artworks through programs like Illuminarty.ai (Munir, et al., 2021). The issue now is not so much who is fraudulent, but which is fraudulent.

Accurately discerning differences between AI models’ artworks through machine learning has yet to be tapped into, despite the concerns about AI image generation and general misuse of AI. To combat the gap in the research and technology, this project aims to create an accurate model that will determine what AI model generated an image. I will use images from the models Midjourney and DALL-E and use a Data-efficient Image Transformer (DeiT) to predict the model that created it. DeiT will be effective as it is pre-trained, accessible, efficient, and able to be finely tuned. I will be using Midjourney and DALL-E because they have widely available datasets, and are the most commonly used image generation programs. It is hypothesized that it is possible to accurately determine the specific AI model that generated an image using machine learning techniques.

SOURCES:
Bird, J. J., & Lotfi, A. (2024). CIFAKE: Image classification and explainable identification of AI-generated synthetic images. Institute of Electrical and Electronics Engineers, 15642-15650.

Bontridder, N., & Poullet, Y. (2021). The role of artificial intelligence in disinformation. Cambridge University Press.
Feldman, E. (2023, January 24). Are A.I. image generators violating copyright laws? Smithsonian Magazine. https://www.smithsonianmag.com/smart-news/are-ai-image-generators-stealing-from-artists-180981488/

Munir, S., Batool, B., Shafiq, Z., Srinivasan, P., & Zaffar, F. (2021). Through the looking glass: Learning to attribute synthetic text generated by language models. Association for Computational Linguistics, 1811-1822.

Roose, K. (2022, September 2). An AI-generated picture won an art prize. Artists aren't happy. New York Times.

Uchendu, A., Le, T., Shu, K., & Lee, D. (2020). Authorship attribution for neural text generation. Association for Computational Linguistics, 8384-8395.
